# ğŸ§  Human Activity Recognition (HAR) using CNN + LSTM

## ğŸ“Œ Overview
This project implements **Human Activity Recognition (HAR)** using the **UFC dataset**.  
We combine **Convolutional Neural Networks (CNNs)** and **Long Short-Term Memory (LSTM)** networks to recognize human activities from video sequences.

- **CNN** extracts **spatial features** from video frames.
- **LSTM** captures **temporal dependencies** across frames.
- Together, the model learns **motion patterns** for accurate activity recognition.

---

## ğŸ“‚ Dataset: UFC Dataset
- The **UFC dataset** contains video clips of various human activities.
- Preprocessing steps:
  - Extract frames from each video.
  - Resize frames (e.g., 128Ã—128).
  - Normalize pixel values.
  - Group frames into sequences (e.g., 30 frames per sequence).

---

## âš™ï¸ Methodology / Workflow

### Steps
1. **Data Preprocessing**
   - Extract and preprocess frames from videos.
   - Generate fixed-length frame sequences.

2. **Feature Extraction (CNN)**
   - A CNN learns **spatial patterns** from each frame.

3. **Temporal Modeling (LSTM)**
   - LSTM processes sequences of CNN features.
   - Captures **time-based activity patterns**.

4. **Classification**
   - Dense + Softmax layer predicts activity labels.

---

### ğŸ”„ Workflow Diagram

flowchart TD

    A[Video Dataset (UFC)] --> B[Frame Extraction & Preprocessing]
    B --> C[CNN Feature Extraction]
    C --> D[LSTM Sequence Modeling]
    D --> E[Dense Layer + Softmax]
    E --> F[Activity Prediction]
    
ğŸ“Š Model Architecture
CNN Layers â†’ Convolution + MaxPooling

LSTM Layer â†’ Captures sequence patterns

Dense + Softmax â†’ Multi-class classification

ğŸš€ Results
Achieved ~70-75% accuracy on validation set.

Successfully recognizes multiple activities such as:

Walking

Running

Punching

Kicking
(depends on dataset classes)

ğŸ“ Repository Structure
bash
Copy code
â”œâ”€â”€ data/               # UFC dataset (preprocessed frames)
â”œâ”€â”€ src/                # Source code
â”‚   â”œâ”€â”€ preprocess.py   # Frame extraction & preprocessing
â”‚   â”œâ”€â”€ model.py        # CNN + LSTM architecture
â”‚   â”œâ”€â”€ train.py        # Training script
â”‚   â””â”€â”€ evaluate.py     # Model evaluation
â”œâ”€â”€ notebooks/          # Jupyter notebooks for experiments
â”œâ”€â”€ results/            # Training logs, plots
â””â”€â”€ README.md           # Project description
âš¡ Installation & Usage
1. Clone the repository
bash
Copy code
git clone https://github.com/your-username/human-activity-recognition.git
cd human-activity-recognition
2. Install dependencies
bash
Copy code
pip install -r requirements.txt
3. Prepare dataset
Download UFC dataset.

Place it inside the data/ folder.

Run preprocessing:

bash
Copy code
python src/preprocess.py
4. Train the model
bash
Copy code
python src/train.py
5. Evaluate the model
bash
Copy code
python src/evaluate.py
ğŸ”® Future Enhancements
âœ… Add more activity classes.

âœ… Experiment with 3D CNNs and Transformers.

âœ… Deploy as a real-time recognition system.

âœ… Integrate with mobile/edge devices.

ğŸ™Œ Acknowledgements
UFC Dataset

TensorFlow / Keras / PyTorch (depending on implementation)

Research papers on CNN+LSTM based HAR
